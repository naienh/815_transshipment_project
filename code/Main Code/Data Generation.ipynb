{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import system\n",
    "from glob import glob\n",
    "import csv\n",
    "import os\n",
    "from random import seed, uniform\n",
    "from string import ascii_uppercase\n",
    "import json\n",
    "import requests, zipfile, io\n",
    "\n",
    "# import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x1,x2):\n",
    "    dx = x1[0] - x2[0]\n",
    "    dy = x1[1] - x2[1]\n",
    "    return (dx**2 + dy**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "random_state = 912"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Status: True\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://www.sintef.no/contentassets/1338af68996841d3922bc8e87adc430c/pdp_100.zip')\n",
    "print('Download Status:',response.ok)\n",
    "z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "z.extractall('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing all files in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pdp_100/lc101.txt', 'pdp_100/lc102.txt', 'pdp_100/lc103.txt', 'pdp_100/lc104.txt', 'pdp_100/lc105.txt', 'pdp_100/lc106.txt', 'pdp_100/lc107.txt', 'pdp_100/lc108.txt', 'pdp_100/lc109.txt', 'pdp_100/lc201.txt', 'pdp_100/lc202.txt', 'pdp_100/lc203.txt', 'pdp_100/lc204.txt', 'pdp_100/lc205.txt', 'pdp_100/lc206.txt', 'pdp_100/lc207.txt', 'pdp_100/lc208.txt', 'pdp_100/lr101.txt', 'pdp_100/lr102.txt', 'pdp_100/lr103.txt', 'pdp_100/lr104.txt', 'pdp_100/lr105.txt', 'pdp_100/lr106.txt', 'pdp_100/lr107.txt', 'pdp_100/lr108.txt', 'pdp_100/lr109.txt', 'pdp_100/lr110.txt', 'pdp_100/lr111.txt', 'pdp_100/lr112.txt', 'pdp_100/lr201.txt', 'pdp_100/lr202.txt', 'pdp_100/lr203.txt', 'pdp_100/lr204.txt', 'pdp_100/lr205.txt', 'pdp_100/lr206.txt', 'pdp_100/lr207.txt', 'pdp_100/lr208.txt', 'pdp_100/lr209.txt', 'pdp_100/lr210.txt', 'pdp_100/lr211.txt', 'pdp_100/lrc101.txt', 'pdp_100/lrc102.txt', 'pdp_100/lrc103.txt', 'pdp_100/lrc104.txt', 'pdp_100/lrc105.txt', 'pdp_100/lrc106.txt', 'pdp_100/lrc107.txt', 'pdp_100/lrc108.txt', 'pdp_100/lrc201.txt', 'pdp_100/lrc202.txt', 'pdp_100/lrc203.txt', 'pdp_100/lrc204.txt', 'pdp_100/lrc205.txt', 'pdp_100/lrc206.txt', 'pdp_100/lrc207.txt', 'pdp_100/lrc208.txt']\n",
      "\n",
      "Begin processing 56 original datasets.\n"
     ]
    }
   ],
   "source": [
    "# list of files in the Li & Lim benchmark\n",
    "# https://www.sintef.no/projectweb/top/pdptw/li-lim-benchmark/\n",
    "file_list = sorted(glob('pdp_100/*.txt'))\n",
    "print(file_list)\n",
    "print('\\nBegin processing {} original datasets.'.format(len(file_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(num_of_nodes,time_window):\n",
    "    # set seed\n",
    "    seed(random_state)\n",
    "    np.random.seed(seed=random_state)\n",
    "    # check the parameters\n",
    "    assert num_of_nodes % 2 == 0\n",
    "    assert time_window == True or time_window == False\n",
    "    \n",
    "    num_of_customer = int(num_of_nodes / 2)\n",
    "    double_letter_set = ['{}{}'.format(ascii_uppercase[i],ascii_uppercase[j]) for i in range(26) for j in range(26)]\n",
    "\n",
    "    for n,file_name in enumerate(file_list):\n",
    "        pickup, delivery = [], []\n",
    "\n",
    "        ''' get information from the datafile\n",
    "        '''\n",
    "        with open(file_name,'r') as f:\n",
    "            for i,line in enumerate(f):\n",
    "                # skip the first two lines\n",
    "                if i == 0: \n",
    "                    speed = float(line.replace('\\n','').split('\\t')[-1])\n",
    "                    # apprently some files have speed = 0\n",
    "                    speed = speed if speed != 0 else 1\n",
    "                if i <= 1: continue\n",
    "                # read lines until pick-up and dilvery information is collected\n",
    "                cache = [float(piece) for piece in line.replace('\\n','').split('\\t')]\n",
    "                # if delivery\n",
    "                if cache[-1] == 0 and len(delivery) < num_of_customer:\n",
    "                    delivery.append(cache)\n",
    "                elif cache[-2] == 0 and len(pickup) < num_of_customer:\n",
    "                    pickup.append(cache)\n",
    "                if len(pickup) == num_of_customer and len(delivery) == num_of_customer:\n",
    "                    break\n",
    "\n",
    "        ''' start and end depot, and other depots\n",
    "        '''\n",
    "        x_range = [case[1] for case in pickup+delivery]\n",
    "        y_range = [case[2] for case in pickup+delivery]\n",
    "        x_min, x_max = min(x_range), max(x_range)\n",
    "        y_min, y_max = min(y_range), max(y_range)\n",
    "        start_depot = [(uniform(x_min,x_max),uniform(y_min,y_max)) for _ in range(num_of_customer)]\n",
    "        end_depot = [(uniform(x_min,x_max),uniform(y_min,y_max)) for _ in range(num_of_customer)]\n",
    "\n",
    "        pickup_depot = [(case[1],case[2]) for case in pickup]\n",
    "        delivery_depot = [(case[1],case[2]) for case in delivery]\n",
    "        all_depots = pickup_depot + delivery_depot + start_depot + end_depot\n",
    "\n",
    "        ''' vehicle capacity\n",
    "        '''\n",
    "        mean_demand = np.mean([case[3] for case in pickup])\n",
    "        max_demand = max([case[3] for case in pickup])\n",
    "        min_demand = min([case[3] for case in pickup])\n",
    "        capacity = [max(np.random.normal(1*mean_demand,0.4*mean_demand),min_demand) for _ in range(num_of_customer)]\n",
    "        # fix the last one to be max demand\n",
    "        capacity[-1] = max_demand\n",
    "\n",
    "        ''' cost factor for each vehicle\n",
    "        '''\n",
    "        cost_factor = sorted([20*np.random.normal(1,0.2) for _ in range(num_of_customer)])\n",
    "        correct_order = sorted(range(num_of_customer), key = capacity.__getitem__)\n",
    "        cost_factor = [cost_factor[indices] for indices in correct_order]\n",
    "\n",
    "        ''' get the timewindow to half\n",
    "        '''\n",
    "        for _ in range(num_of_customer):\n",
    "            pickup[_][4] /= 2\n",
    "            pickup[_][5] /= 2\n",
    "            delivery[_][4] /= 2\n",
    "            delivery[_][5] /= 2\n",
    "\n",
    "        ''' write to .dat file\n",
    "        '''\n",
    "        folder_name = './processed_data_{}_nodes_no_time_window/'.format(num_of_nodes) if not time_window \\\n",
    "                        else './processed_data_{}_nodes_yes_time_window/'.format(num_of_nodes)\n",
    "        \n",
    "        os.makedirs(folder_name,exist_ok=True)\n",
    "        \n",
    "        with open(folder_name+os.path.split(file_name)[-1].replace('.txt','.dat'),'w') as writer:\n",
    "            if n == len(file_list)-1: print('Writing data to:',folder_name)\n",
    "            # set of all nodes\n",
    "            writer.write('set N := ')\n",
    "            writer.write(' '.join(double_letter_set[:4*num_of_customer]))\n",
    "            writer.write(';\\n\\n')\n",
    "            # set of transhipment nodes, exclude start and end depot\n",
    "            writer.write('set T := ')\n",
    "            writer.write(' '.join(double_letter_set[:2*num_of_customer]))\n",
    "            writer.write(';\\n\\n')\n",
    "            # vehicle data\n",
    "            writer.write('table\\tK={K}\\tu(K)\\to(K)\\to_(K):\\n')\n",
    "            writer.write('\\tK\\tu\\to\\to_\\t:=\\n')\n",
    "            for k in range(num_of_customer):\n",
    "                writer.write('\\t{:d}\\t{:.2f}\\t{:}\\t{:}\\n'\n",
    "                             .format(k+1,capacity[k],double_letter_set[2*num_of_customer+2*k],double_letter_set[2*num_of_customer+2*k+1]))\n",
    "            writer.write(';\\n\\n')\n",
    "            # cost data\n",
    "            writer.write('param c default 0 :=\\n')\n",
    "            for i in range(4*num_of_customer):\n",
    "                for j in range(4*num_of_customer):\n",
    "                    if i == j: continue\n",
    "                    # if both are between start and end depots, then continue\n",
    "                    if i >= 2*num_of_customer and j >= 2*num_of_customer: continue\n",
    "                    for k in range(num_of_customer):\n",
    "                        distance = norm(all_depots[i],all_depots[j])\n",
    "                        writer.write('{:}\\t{:}\\t{:d}\\t{:.2f}\\n'\n",
    "                                     .format(double_letter_set[i],double_letter_set[j],k+1,distance*cost_factor[k]))\n",
    "            writer.write(';\\n\\n')\n",
    "\n",
    "            # time data\n",
    "            if time_window:\n",
    "                writer.write('param tau default 0 :=\\n')\n",
    "                for i in range(4*num_of_customer):\n",
    "                    for j in range(4*num_of_customer):\n",
    "                        if i == j: continue\n",
    "                        if i >= 2*num_of_customer and j >= 2*num_of_customer: continue\n",
    "                        for k in range(num_of_customer):\n",
    "                            distance = norm(all_depots[i],all_depots[j])\n",
    "                            writer.write('{:}\\t{:}\\t{:d}\\t{:.2f}\\n'\n",
    "                                         .format(double_letter_set[i],double_letter_set[j],k+1,distance/speed))\n",
    "                writer.write(';\\n\\n')\n",
    "\n",
    "            # request data\n",
    "            demand = [case[3] for case in pickup]\n",
    "            writer.write('table R={R}  q(R)  p(R)  d(R):\\n')\n",
    "            writer.write('\\tR\\tq\\tp\\td\\t:=\\n')\n",
    "            for i in range(num_of_customer):\n",
    "                writer.write('\\t{:}\\t{:}\\t{:}\\t{:}\\n'\n",
    "                             .format(i+1,demand[i],double_letter_set[i],double_letter_set[i+num_of_customer]))\n",
    "            writer.write(';\\n\\n')\n",
    "            \n",
    "            # request time data\n",
    "            min_tranport_time = [norm(all_depots[j],all_depots[j+num_of_customer])/speed \\\n",
    "                      for j in range(num_of_customer)]\n",
    "            # we need to do a check if the time window is consistent (min time is left)\n",
    "            arrival_time = [case[4] for case in pickup]\\\n",
    "            + [max(case[4],2*min_tranport_time[i]+pickup[i][4]) for i,case in enumerate(delivery)]\n",
    "            depart_time = [case[5] for case in pickup]\\\n",
    "            + [max(case[5],2*min_tranport_time[i]+pickup[i][5]) for i,case in enumerate(delivery)]\n",
    "\n",
    "            if time_window:\n",
    "                writer.write('param : t_e t_l :=\\n')\n",
    "                for i in range(2*num_of_customer):\n",
    "                    writer.write('\\t{:}\\t{:.2f}\\t{:.2f}\\t\\n'\n",
    "                                 .format(double_letter_set[i],arrival_time[i],depart_time[i]))\n",
    "                writer.write(';\\n\\n')\n",
    "\n",
    "        # write an extra pickle file to store the location in a dictionary\n",
    "        location_dic = {}\n",
    "        for i in range(4*num_of_customer):\n",
    "            location_dic[double_letter_set[i]] = all_depots[i]\n",
    "\n",
    "        with open(folder_name+os.path.split(file_name)[-1].replace('.txt','.json'), 'w') as handle:\n",
    "            json.dump(location_dic, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write 4 different sets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to: ./processed_data_10_nodes_no_time_window/\n",
      "Writing data to: ./processed_data_10_nodes_yes_time_window/\n",
      "Writing data to: ./processed_data_14_nodes_no_time_window/\n",
      "Writing data to: ./processed_data_14_nodes_yes_time_window/\n"
     ]
    }
   ],
   "source": [
    "write_data(10,time_window=False)\n",
    "write_data(10,time_window=True)\n",
    "write_data(14,time_window=False)\n",
    "write_data(14,time_window=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
